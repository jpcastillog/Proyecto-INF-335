{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://www.exalumnos.usm.cl/wp-content/uploads/2015/06/Isotipo-Negro.gif\" title=\"Title text\" width=\"20%\" height=\"20%\" />\n",
    "\n",
    "\n",
    "<hr style=\"height:2px;border:none\"/>\n",
    "<h3 align='center'> INF-335 Tecnolog√≠as de B√∫squeda en la Web</h3>\n",
    "\n",
    "<H1 align='center'> An√°lisis de Comentarios en Twitter Respecto al Acontecer Nacional Actual </H1>\n",
    "<hr style=\"height:2px;border:none\"/>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import twint \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import word_tokenize, WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lectura de Tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>conversation_id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "      <th>timezone</th>\n",
       "      <th>user_id</th>\n",
       "      <th>username</th>\n",
       "      <th>name</th>\n",
       "      <th>place</th>\n",
       "      <th>...</th>\n",
       "      <th>video</th>\n",
       "      <th>near</th>\n",
       "      <th>user_rt_id</th>\n",
       "      <th>user_rt</th>\n",
       "      <th>retweet_id</th>\n",
       "      <th>reply_to</th>\n",
       "      <th>retweet_date</th>\n",
       "      <th>translate</th>\n",
       "      <th>trans_src</th>\n",
       "      <th>trans_dest</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1187881524559003648</td>\n",
       "      <td>1187881524559003648</td>\n",
       "      <td>1572047999000</td>\n",
       "      <td>2019-10-25</td>\n",
       "      <td>20:59:59</td>\n",
       "      <td>-3</td>\n",
       "      <td>56182537</td>\n",
       "      <td>axcarhen</td>\n",
       "      <td>alex</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[{'user_id': '56182537', 'username': 'axcarhen'}]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1187881522877161472</td>\n",
       "      <td>1187881522877161472</td>\n",
       "      <td>1572047999000</td>\n",
       "      <td>2019-10-25</td>\n",
       "      <td>20:59:59</td>\n",
       "      <td>-3</td>\n",
       "      <td>289545711</td>\n",
       "      <td>taengooiu</td>\n",
       "      <td>ùíàùíÇùíÉùíä ü¶ãüá®üá±</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[{'user_id': '289545711', 'username': 'taengoo...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1187881520993841156</td>\n",
       "      <td>1187881520993841156</td>\n",
       "      <td>1572047999000</td>\n",
       "      <td>2019-10-25</td>\n",
       "      <td>20:59:59</td>\n",
       "      <td>-3</td>\n",
       "      <td>310003737</td>\n",
       "      <td>twerkinghyuk_</td>\n",
       "      <td>Karen üåà Frente Patri√≥tico Super Junior ‚úäüèª</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[{'user_id': '310003737', 'username': 'twerkin...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1187881520905838593</td>\n",
       "      <td>1187881520905838593</td>\n",
       "      <td>1572047999000</td>\n",
       "      <td>2019-10-25</td>\n",
       "      <td>20:59:59</td>\n",
       "      <td>-3</td>\n",
       "      <td>2941623273</td>\n",
       "      <td>emiliorreyes</td>\n",
       "      <td>APRUEBO PO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[{'user_id': '2941623273', 'username': 'emilio...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1187881519047696384</td>\n",
       "      <td>1187842485315354624</td>\n",
       "      <td>1572047998000</td>\n",
       "      <td>2019-10-25</td>\n",
       "      <td>20:59:58</td>\n",
       "      <td>-3</td>\n",
       "      <td>382904289</td>\n",
       "      <td>gabulethon</td>\n",
       "      <td>#RenunciaPi√±era</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[{'user_id': '382904289', 'username': 'gabulet...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10041</td>\n",
       "      <td>1193940701471358978</td>\n",
       "      <td>1193940701471358978</td>\n",
       "      <td>1573492620000</td>\n",
       "      <td>2019-11-11</td>\n",
       "      <td>14:17:00</td>\n",
       "      <td>-3</td>\n",
       "      <td>191894994</td>\n",
       "      <td>rsumen</td>\n",
       "      <td>Peri√≥dico Resumen</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[{'user_id': '191894994', 'username': 'rsumen'}]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10042</td>\n",
       "      <td>1193940594164404224</td>\n",
       "      <td>1193940594164404224</td>\n",
       "      <td>1573492594000</td>\n",
       "      <td>2019-11-11</td>\n",
       "      <td>14:16:34</td>\n",
       "      <td>-3</td>\n",
       "      <td>26631822</td>\n",
       "      <td>mavaldess</td>\n",
       "      <td>Macarena Vald√©s</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[{'user_id': '26631822', 'username': 'Mavaldes...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10043</td>\n",
       "      <td>1193940128881946625</td>\n",
       "      <td>1193940128881946625</td>\n",
       "      <td>1573492483000</td>\n",
       "      <td>2019-11-11</td>\n",
       "      <td>14:14:43</td>\n",
       "      <td>-3</td>\n",
       "      <td>847976433989427200</td>\n",
       "      <td>frantibiotico</td>\n",
       "      <td>Fran</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[{'user_id': '847976433989427200', 'username':...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10044</td>\n",
       "      <td>1193940087614189569</td>\n",
       "      <td>1193940087614189569</td>\n",
       "      <td>1573492473000</td>\n",
       "      <td>2019-11-11</td>\n",
       "      <td>14:14:33</td>\n",
       "      <td>-3</td>\n",
       "      <td>1136420579639201792</td>\n",
       "      <td>douglaspastor5</td>\n",
       "      <td>‚ú≥Ô∏èDOUG üá®üá±</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[{'user_id': '1136420579639201792', 'username'...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10045</td>\n",
       "      <td>1193939915651846144</td>\n",
       "      <td>1193939915651846144</td>\n",
       "      <td>1573492432000</td>\n",
       "      <td>2019-11-11</td>\n",
       "      <td>14:13:52</td>\n",
       "      <td>-3</td>\n",
       "      <td>1136420579639201792</td>\n",
       "      <td>douglaspastor5</td>\n",
       "      <td>‚ú≥Ô∏èDOUG üá®üá±</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[{'user_id': '1136420579639201792', 'username'...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10046 rows √ó 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        id      conversation_id     created_at        date  \\\n",
       "0      1187881524559003648  1187881524559003648  1572047999000  2019-10-25   \n",
       "1      1187881522877161472  1187881522877161472  1572047999000  2019-10-25   \n",
       "2      1187881520993841156  1187881520993841156  1572047999000  2019-10-25   \n",
       "3      1187881520905838593  1187881520905838593  1572047999000  2019-10-25   \n",
       "4      1187881519047696384  1187842485315354624  1572047998000  2019-10-25   \n",
       "...                    ...                  ...            ...         ...   \n",
       "10041  1193940701471358978  1193940701471358978  1573492620000  2019-11-11   \n",
       "10042  1193940594164404224  1193940594164404224  1573492594000  2019-11-11   \n",
       "10043  1193940128881946625  1193940128881946625  1573492483000  2019-11-11   \n",
       "10044  1193940087614189569  1193940087614189569  1573492473000  2019-11-11   \n",
       "10045  1193939915651846144  1193939915651846144  1573492432000  2019-11-11   \n",
       "\n",
       "           time  timezone              user_id        username  \\\n",
       "0      20:59:59        -3             56182537        axcarhen   \n",
       "1      20:59:59        -3            289545711       taengooiu   \n",
       "2      20:59:59        -3            310003737   twerkinghyuk_   \n",
       "3      20:59:59        -3           2941623273    emiliorreyes   \n",
       "4      20:59:58        -3            382904289      gabulethon   \n",
       "...         ...       ...                  ...             ...   \n",
       "10041  14:17:00        -3            191894994          rsumen   \n",
       "10042  14:16:34        -3             26631822       mavaldess   \n",
       "10043  14:14:43        -3   847976433989427200   frantibiotico   \n",
       "10044  14:14:33        -3  1136420579639201792  douglaspastor5   \n",
       "10045  14:13:52        -3  1136420579639201792  douglaspastor5   \n",
       "\n",
       "                                            name place  ... video near  \\\n",
       "0                                           alex   NaN  ...     0  NaN   \n",
       "1                                       ùíàùíÇùíÉùíä ü¶ãüá®üá±   NaN  ...     0  NaN   \n",
       "2      Karen üåà Frente Patri√≥tico Super Junior ‚úäüèª   NaN  ...     0  NaN   \n",
       "3                                     APRUEBO PO   NaN  ...     1  NaN   \n",
       "4                                #RenunciaPi√±era   NaN  ...     0  NaN   \n",
       "...                                          ...   ...  ...   ...  ...   \n",
       "10041                          Peri√≥dico Resumen   NaN  ...     0  NaN   \n",
       "10042                            Macarena Vald√©s   NaN  ...     0  NaN   \n",
       "10043                                       Fran   NaN  ...     0  NaN   \n",
       "10044                                  ‚ú≥Ô∏èDOUG üá®üá±   NaN  ...     0  NaN   \n",
       "10045                                  ‚ú≥Ô∏èDOUG üá®üá±   NaN  ...     0  NaN   \n",
       "\n",
       "      user_rt_id user_rt  retweet_id  \\\n",
       "0            NaN     NaN         NaN   \n",
       "1            NaN     NaN         NaN   \n",
       "2            NaN     NaN         NaN   \n",
       "3            NaN     NaN         NaN   \n",
       "4            NaN     NaN         NaN   \n",
       "...          ...     ...         ...   \n",
       "10041        NaN     NaN         NaN   \n",
       "10042        NaN     NaN         NaN   \n",
       "10043        NaN     NaN         NaN   \n",
       "10044        NaN     NaN         NaN   \n",
       "10045        NaN     NaN         NaN   \n",
       "\n",
       "                                                reply_to  retweet_date  \\\n",
       "0      [{'user_id': '56182537', 'username': 'axcarhen'}]           NaN   \n",
       "1      [{'user_id': '289545711', 'username': 'taengoo...           NaN   \n",
       "2      [{'user_id': '310003737', 'username': 'twerkin...           NaN   \n",
       "3      [{'user_id': '2941623273', 'username': 'emilio...           NaN   \n",
       "4      [{'user_id': '382904289', 'username': 'gabulet...           NaN   \n",
       "...                                                  ...           ...   \n",
       "10041   [{'user_id': '191894994', 'username': 'rsumen'}]           NaN   \n",
       "10042  [{'user_id': '26631822', 'username': 'Mavaldes...           NaN   \n",
       "10043  [{'user_id': '847976433989427200', 'username':...           NaN   \n",
       "10044  [{'user_id': '1136420579639201792', 'username'...           NaN   \n",
       "10045  [{'user_id': '1136420579639201792', 'username'...           NaN   \n",
       "\n",
       "      translate trans_src  trans_dest  \n",
       "0           NaN       NaN         NaN  \n",
       "1           NaN       NaN         NaN  \n",
       "2           NaN       NaN         NaN  \n",
       "3           NaN       NaN         NaN  \n",
       "4           NaN       NaN         NaN  \n",
       "...         ...       ...         ...  \n",
       "10041       NaN       NaN         NaN  \n",
       "10042       NaN       NaN         NaN  \n",
       "10043       NaN       NaN         NaN  \n",
       "10044       NaN       NaN         NaN  \n",
       "10045       NaN       NaN         NaN  \n",
       "\n",
       "[10046 rows x 31 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./temp_files/all_data.csv', encoding='utf-8')\n",
    "df.drop(columns=['hashtags', 'geo', 'source'], inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Limpieza de Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funci√≥n para quitar emojis\n",
    "def deEmojify(inputString):\n",
    "    return inputString.encode('ascii', 'ignore').decode('ascii')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        ojal√° les quede claro que no queremos migajas ...\n",
       "1        ha sido 1 semana de sufrimiento de cansancio f...\n",
       "2        este cabro con su tranquilidad y el que pregun...\n",
       "3        se me eriza la piel al escuchar esto, todos un...\n",
       "4        si tienes a m√°s de un mill√≥n de personas march...\n",
       "                               ...                        \n",
       "10041    el historial del tirador de re√±aca y su milita...\n",
       "10042    no es que no entienda nada, es que le encanta ...\n",
       "10043    los pacos llevan f√°cilmente 30 min tirando lac...\n",
       "10044    tiempos peores por eso es importante votar #ch...\n",
       "10045    tiempos peores por eso es importante votar #ch...\n",
       "Name: tweet, Length: 10046, dtype: object"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "import emoji\n",
    "\n",
    "#otra funci√≥n para quitar emojis, usando el paquete emoji\n",
    "def freemoji(text):\n",
    "    allchars = [str for str in text]\n",
    "    emoji_list = [c for c in allchars if c in emoji.UNICODE_EMOJI]\n",
    "    clean_text = ' '.join([str for str in text.split() if not any(i in str for i in emoji_list)])\n",
    "    return clean_text\n",
    "\n",
    "df[\"tweet\"] = df[\"tweet\"].str.lower()\n",
    "df[\"tweet\"]=df['tweet'].apply(lambda x: re.split('https:\\/\\/.*', str(x))[0])\n",
    "df[\"tweet\"]=df['tweet'].apply(lambda x: re.split('pic.twitter.com/.*', str(x))[0])\n",
    "df[\"tweet\"]=df['tweet'].apply(lambda x: re.split('http //.*', str(x))[0])\n",
    "tweets=df['tweet'].apply(freemoji)\n",
    "tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize(word, corpus='nltk'):\n",
    "    if corpus == 'nltk':\n",
    "        lemmatizer = WordNetLemmatizer()\n",
    "        return lemmatizer.lemmatize(word)\n",
    "\n",
    "def tokenize(data, corpus='nltk'):\n",
    "    stop_words = stopwords.words('spanish')\n",
    "    others_stop=[\"'\",\"...\",\"''\",\"#\",\"<\",\">\",\"}\",\"{\",\"]\",\"[\",\"¬¥\",\"?\",\"¬°\",\"!\",\"¬ø\",\"/\",\"*\",\n",
    "                '\"',\"-\",\"--\",\";\",\":\",\"::\",\"=\",\")\",\"(\",\"&\",\"|\",\"'ve\",\"'t\",\"'s\",\n",
    "                \"'ll\",\"n't\",\">.<\",\"<3\",\"._.\",\"~\",\"<br\",\"</\",\"/>\",\"<<\",\">>\",\"~~\",\n",
    "                \",\",\"d\",\"na\",\"m\",\"''\",\"¬¥¬¥\",\"!!!!!\",'\"(','\",','.;','[*','tm','\").',\n",
    "               \"l\",'\"&',').*','://','www','http','\"...',\"=[\", '@', '``']\n",
    "    stop_words += others_stop\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    tokenize_data = []\n",
    "    for text in data:\n",
    "        word_tokens = word_tokenize(text)\n",
    "        words = ''\n",
    "        for word in word_tokens:\n",
    "            if (word not in stop_words) and len(word) > 3:\n",
    "                if corpus == 'nltk':\n",
    "                    words += ' ' + lemmatize(word)\n",
    "        tokenize_data += [words]\n",
    "    return tokenize_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "tok = tokenize(tweets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDING_DIM = 300\n",
    "FILE = ''\n",
    "embeddings_index = {}\n",
    "# Load embeddings\n",
    "with open(FILE) as file:\n",
    "    for line in file:\n",
    "        values = line.split()\n",
    "        embeddings_index[values[0]] = np.asarray(values[1:], dtype = 'float32') \n",
    "\n",
    "def generate_feature_matrix(sentences):\n",
    "    feature_matrix = np.empty(0,0)\n",
    "    for sentence in sentences:\n",
    "        words = sentence.split()\n",
    "        words_matrix = np.empty(0,0)\n",
    "        for word in words:\n",
    "            try:\n",
    "                emb_vector = embeddings_index.get(word)\n",
    "            except:\n",
    "                emb_vector = np.zeros(EMBEDDING_DIM)\n",
    "            \n",
    "            if words_matrix.shape == (0,0):\n",
    "                words_matrix = emb_vector[np.newaxis,:]\n",
    "            else:\n",
    "                np.concatenate((words_matrix, emb_vector[np.newaxis,:]), axis=0)\n",
    "        awe_sentence = words_matrix.mean(0)\n",
    "        \n",
    "        if feature_matrix.shape == (0,0):\n",
    "            feature_matrix = awe_sentence[np.newaxis,:]\n",
    "        else:\n",
    "            np.concatenate((feature_matrix,awe_sentence[np.new_axis,:]), axis=0)\n",
    "    return feature_matrix\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Corpus TASS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['general-test-tagged.xml', 'general-train-tagged.xml', 'general-train-tagged-3l.xml', 'politics-test-tagged.xml', 'general-test-tagged-3l.xml']\n",
      "general-test-tagged.xml\n",
      "general-train-tagged.xml\n",
      "general-train-tagged-3l.xml\n",
      "politics-test-tagged.xml\n",
      "general-test-tagged-3l.xml\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "from lxml import objectify\n",
    "extension = 'xml'\n",
    "def merge_corpus(dir):\n",
    "    os.chdir(dir)\n",
    "    file_names = [i for i in glob.glob(f'*.{extension}')]\n",
    "    all_df = []\n",
    "    print(file_names)\n",
    "    for file in file_names:\n",
    "        print(file)\n",
    "        xml = objectify.parse(open(file, encoding='utf8'))\n",
    "        root = xml.getroot()\n",
    "        tweets_df = pd.DataFrame(columns=['content', 'polarity'])\n",
    "        tweets = root.getchildren()\n",
    "        for i in range(len(tweets)):\n",
    "            tweet = tweets[i]\n",
    "            row = dict(zip(['content', 'polarity'], [tweet.content.text, tweet.sentiments.polarity.value.text]))\n",
    "            row = pd.Series(row)\n",
    "            row.name = i\n",
    "            tweets_df = tweets_df.append(row)\n",
    "        all_df.append(tweets_df)\n",
    "    all_data = pd.concat(all_df)\n",
    "    all_data.to_csv('all_tass.csv', index=False, encoding='utf-8')\n",
    "    \n",
    "merge_corpus('/Users/juancastillo/Desktop/Proyecto-INF-335/tass')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>polarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Portada 'P√∫blico', viernes. Fabra al banquillo...</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Grande! RT @veronicacalderon \"El periodista es...</td>\n",
       "      <td>NONE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Gonzalo Altozano tras la presentaci√≥n de su li...</td>\n",
       "      <td>P+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Ma√±ana en Gaceta: TVE, la que pagamos t√∫ y yo,...</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Qu√© envidia ‚Äú@mfcastineiras: Pedro ma√±ana x la...</td>\n",
       "      <td>NONE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>138529</td>\n",
       "      <td>@Juandecolmenero @angelrubioti @barbara_ruizp ...</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>138530</td>\n",
       "      <td>Escuchan lo que quieren RT @almudenanegro: El ...</td>\n",
       "      <td>NONE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>138531</td>\n",
       "      <td>¬øA qu√© espera el alcalde promarihuana independ...</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>138532</td>\n",
       "      <td>Esto es lo que hay... Preocupante la flagrante...</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>138533</td>\n",
       "      <td>Rajoy, con el agua al cuello: Espa√±a se asoma ...</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>138534 rows √ó 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  content polarity\n",
       "0       Portada 'P√∫blico', viernes. Fabra al banquillo...        N\n",
       "1       Grande! RT @veronicacalderon \"El periodista es...     NONE\n",
       "2       Gonzalo Altozano tras la presentaci√≥n de su li...       P+\n",
       "3       Ma√±ana en Gaceta: TVE, la que pagamos t√∫ y yo,...        N\n",
       "4       Qu√© envidia ‚Äú@mfcastineiras: Pedro ma√±ana x la...     NONE\n",
       "...                                                   ...      ...\n",
       "138529  @Juandecolmenero @angelrubioti @barbara_ruizp ...        P\n",
       "138530  Escuchan lo que quieren RT @almudenanegro: El ...     NONE\n",
       "138531  ¬øA qu√© espera el alcalde promarihuana independ...        N\n",
       "138532  Esto es lo que hay... Preocupante la flagrante...        N\n",
       "138533  Rajoy, con el agua al cuello: Espa√±a se asoma ...        N\n",
       "\n",
       "[138534 rows x 2 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sentiment = pd.read_csv('all_tass.csv')\n",
    "df_sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>polarity</th>\n",
       "      <th>agreement</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Salgo de #VeoTV , que d√≠a m√°s largoooooo...</td>\n",
       "      <td>NONE</td>\n",
       "      <td>AGREEMENT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>@PauladeLasHeras No te libraras de ayudar me/n...</td>\n",
       "      <td>NEU</td>\n",
       "      <td>DISAGREEMENT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>@marodriguezb Gracias MAR</td>\n",
       "      <td>P</td>\n",
       "      <td>AGREEMENT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Off pensando en el regalito Sinde, la que se v...</td>\n",
       "      <td>N+</td>\n",
       "      <td>AGREEMENT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Conozco a alguien q es adicto al drama! Ja ja ...</td>\n",
       "      <td>P+</td>\n",
       "      <td>AGREEMENT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7214</td>\n",
       "      <td>Muy indignante si ...nadie repara en ello hoy ...</td>\n",
       "      <td>N+</td>\n",
       "      <td>AGREEMENT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7215</td>\n",
       "      <td>M√°s pobres por discriminar a la mujer http://t...</td>\n",
       "      <td>N+</td>\n",
       "      <td>AGREEMENT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7216</td>\n",
       "      <td>Crean un banco de productos para mujeres con c...</td>\n",
       "      <td>P</td>\n",
       "      <td>AGREEMENT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7217</td>\n",
       "      <td>Sobre la sorprendente hu√≠da hoy en el Senado d...</td>\n",
       "      <td>N</td>\n",
       "      <td>AGREEMENT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7218</td>\n",
       "      <td>#CorreMarianoCorre est√° muy bien pero la versi...</td>\n",
       "      <td>P+</td>\n",
       "      <td>AGREEMENT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7219 rows √ó 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                content polarity     agreement\n",
       "0           Salgo de #VeoTV , que d√≠a m√°s largoooooo...     NONE     AGREEMENT\n",
       "1     @PauladeLasHeras No te libraras de ayudar me/n...      NEU  DISAGREEMENT\n",
       "2                             @marodriguezb Gracias MAR        P     AGREEMENT\n",
       "3     Off pensando en el regalito Sinde, la que se v...       N+     AGREEMENT\n",
       "4     Conozco a alguien q es adicto al drama! Ja ja ...       P+     AGREEMENT\n",
       "...                                                 ...      ...           ...\n",
       "7214  Muy indignante si ...nadie repara en ello hoy ...       N+     AGREEMENT\n",
       "7215  M√°s pobres por discriminar a la mujer http://t...       N+     AGREEMENT\n",
       "7216  Crean un banco de productos para mujeres con c...        P     AGREEMENT\n",
       "7217  Sobre la sorprendente hu√≠da hoy en el Senado d...        N     AGREEMENT\n",
       "7218  #CorreMarianoCorre est√° muy bien pero la versi...       P+     AGREEMENT\n",
       "\n",
       "[7219 rows x 3 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "general_tweets_corpus_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "train= pd.read_csv('general-tweets-train-tagged.csv', encoding='utf-8')\n",
    "train = train[train['polarity'] != 'NONE']\n",
    "#train = train.query('agreement != \"DISAGREEMENT\" and polarity != \"NONE\"')\n",
    "#remove links\n",
    "train = train[-train.content.str.contains('^http.*$')]\n",
    "\n",
    "#paso de etiquetas a bin y eliminaci√≥n de datos neutros\n",
    "train_corpus = train[train.polarity != 'NEU']\n",
    "pd.options.mode.chained_assignment = None\n",
    "train['polarity_bin'] = 0\n",
    "train.polarity_bin[train.polarity.isin(['P', 'P+'])] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_train=tokenize(train[\"content\"])\n",
    "#definici√≥n de etiqueta\n",
    "eti=train[\"polarity_bin\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/model_selection/_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'C': 0.1, 'kernel': 'linear'}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#gridsearch para determinar hiperpar√°metros con linear svm \n",
    "#from sklearn.cross_validation import cross_val_score\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn import svm\n",
    "\n",
    "\n",
    "vectorizer = CountVectorizer(ngram_range=(1, 1), binary=False) #TF representation\n",
    "\n",
    "vectorizer.fit(tweets_train)\n",
    "tr_v = vectorizer.transform(tweets_train)\n",
    "\n",
    "test_v= vectorizer.transform(tok)\n",
    "\n",
    "\n",
    "parameters = {'kernel':('linear', 'rbf'), 'C':[10**i for i in np.arange(-4,4, dtype=float)]}\n",
    "svc = svm.SVC(gamma=\"auto\")\n",
    "clf = GridSearchCV(svc, parameters)\n",
    "clf.fit(tr_v, eti)\n",
    "clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score del mejor modelo encontrado: 0.9393038306804268\n"
     ]
    }
   ],
   "source": [
    "print(\"Score del mejor modelo encontrado:\", clf.score(tr_v,eti))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment=clf.predict(test_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 0 ... 0 1 1]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>sentiment_svm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>ojal√° les quede claro que no queremos migajas ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>ha sido 1 semana de sufrimiento\\nde cansancio ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>este cabro con su tranquilidad y el que pregun...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>se me eriza la piel al escuchar esto, todos un...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>si tienes a m√°s de un mill√≥n de personas march...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10041</td>\n",
       "      <td>el historial del tirador de re√±aca y su milita...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10042</td>\n",
       "      <td>no es que no entienda nada, es que le encanta ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10043</td>\n",
       "      <td>los pacos llevan f√°cilmente 30 min tirando lac...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10044</td>\n",
       "      <td>tiempos peores üí£‚ö∞Ô∏èüö´üí∞üí∞üò§ por eso es importante v...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10045</td>\n",
       "      <td>tiempos peores üí£‚ö∞Ô∏èüö´üí∞üí∞üò§ por eso es importante v...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10046 rows √ó 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   tweet  sentiment_svm\n",
       "0      ojal√° les quede claro que no queremos migajas ...              1\n",
       "1      ha sido 1 semana de sufrimiento\\nde cansancio ...              0\n",
       "2      este cabro con su tranquilidad y el que pregun...              0\n",
       "3      se me eriza la piel al escuchar esto, todos un...              1\n",
       "4      si tienes a m√°s de un mill√≥n de personas march...              1\n",
       "...                                                  ...            ...\n",
       "10041  el historial del tirador de re√±aca y su milita...              0\n",
       "10042  no es que no entienda nada, es que le encanta ...              1\n",
       "10043  los pacos llevan f√°cilmente 30 min tirando lac...              0\n",
       "10044  tiempos peores üí£‚ö∞Ô∏èüö´üí∞üí∞üò§ por eso es importante v...              1\n",
       "10045  tiempos peores üí£‚ö∞Ô∏èüö´üí∞üí∞üò§ por eso es importante v...              1\n",
       "\n",
       "[10046 rows x 2 columns]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(sentiment)\n",
    "df[\"sentiment_svm\"]=sentiment\n",
    "df.to_csv('output.csv', index=False)\n",
    "df[['tweet', 'sentiment_svm']].to_csv('output.csv', sep = ';',index=False)\n",
    "df[['tweet', 'sentiment_svm']]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
